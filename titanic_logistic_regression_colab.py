# -*- coding: utf-8 -*-
"""Titanic_Logistic_Regression_Colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-d9vrs0UrKYfjBwolj7Psw7UuTIjVNzl

# Titanic Survival Prediction using Logistic Regression
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, roc_curve
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import joblib

"""# **1.data exploration**"""

# Upload Titanic_train.csv datasets
df = pd.read_csv('Titanic_train.csv')
df.head()

# show information
print(df.info())
print(df.describe(include='all'))

# Display the first few rows
print("Initial Data Preview:")
print(df.head())

# histogram
sns.histplot(df['Age'].dropna(), kde=True)
plt.title('Age Distribution')
plt.show()

# boxplot
sns.boxplot(x='Pclass', y='Age', data=df)
plt.title('Age vs Passenger Class')
plt.show()

# pair plot
sns.pairplot(df[['Survived', 'Pclass', 'Age', 'Fare', 'SibSp', 'Parch']], hue='Survived')
plt.show()

# correlation of heatmap
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

"""# **2.Data preprocessing**"""

# Drop irrelevant columns
df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)

# Fill missing values
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Encode categorical features
le = LabelEncoder()
df['Sex'] = le.fit_transform(df['Sex'])
df['Embarked'] = le.fit_transform(df['Embarked'])

# Define features and target
X = df.drop('Survived', axis=1)
y = df['Survived']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## 4. Model Building"""

logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)

"""## 5. Model Evaluation"""

# Predictions
y_pred = logreg.predict(X_test)
y_prob = logreg.predict_proba(X_test)[:, 1]

# Classification report
print("Classification Report:\n", classification_report(y_test, y_pred))

# ROC AUC score
roc_auc = roc_auc_score(y_test, y_prob)
print("ROC AUC Score:", roc_auc)

# Plot ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.show()

"""## 6. Interpretation"""

coefficients = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': logreg.coef_[0]
})
coefficients['Odds Ratio'] = np.exp(coefficients['Coefficient'])
coefficients.sort_values(by='Odds Ratio', ascending=False, inplace=True)
print(coefficients)

"""## 7. Save Model"""

# Save model and encoders
joblib.dump(logreg, 'logistic_model.pkl')
joblib.dump(le, 'label_encoder.pkl')

